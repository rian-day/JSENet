# -----------------------------------#
# Parameters of the training session #
# -----------------------------------#

# Input parameters
# ****************

dataset = S3DIS
network_model = cloud_segmentation_dual
num_classes = 13
in_points_dim = 3
in_features_dim = 5
in_radius = 2.000
input_threads = 2

# Model parameters
# ****************

architecture = simple resnetb resnetb_strided resnetb resnetb_strided resnetb resnetb_strided resnetb resnetb_strided resnetb nearest_upsample unary nearest_upsample unary nearest_upsample unary nearest_upsample unary
num_layers = 5
first_features_dim = 64
use_batch_norm = 1
batch_norm_momentum = 0.980

segmentation_ratio = 1.000

# KPConv parameters
# *****************

first_subsampling_dl = 0.040
num_kernel_points = 15
density_parameter = 5.000
fixed_kernel_points = center
KP_extent = 1.000
KP_influence = linear
convolution_mode = sum
trainable_positions = 0

modulated = 0

# Training parameters
# *******************

learning_rate = 0.010000
momentum = 0.980000
lr_decay_epochs = 1:0.977237 2:0.977237 3:0.977237 4:0.977237 5:0.977237 6:0.977237 7:0.977237 8:0.977237 9:0.977237 10:0.977237 11:0.977237 12:0.977237 13:0.977237 14:0.977237 15:0.977237 16:0.977237 17:0.977237 18:0.977237 19:0.977237 20:0.977237 21:0.977237 22:0.977237 23:0.977237 24:0.977237 25:0.977237 26:0.977237 27:0.977237 28:0.977237 29:0.977237 30:0.977237 31:0.977237 32:0.977237 33:0.977237 34:0.977237 35:0.977237 36:0.977237 37:0.977237 38:0.977237 39:0.977237 40:0.977237 41:0.977237 42:0.977237 43:0.977237 44:0.977237 45:0.977237 46:0.977237 47:0.977237 48:0.977237 49:0.977237 50:0.977237 51:0.977237 52:0.977237 53:0.977237 54:0.977237 55:0.977237 56:0.977237 57:0.977237 58:0.977237 59:0.977237 60:0.977237 61:0.977237 62:0.977237 63:0.977237 64:0.977237 65:0.977237 66:0.977237 67:0.977237 68:0.977237 69:0.977237 70:0.977237 71:0.977237 72:0.977237 73:0.977237 74:0.977237 75:0.977237 76:0.977237 77:0.977237 78:0.977237 79:0.977237 80:0.977237 81:0.977237 82:0.977237 83:0.977237 84:0.977237 85:0.977237 86:0.977237 87:0.977237 88:0.977237 89:0.977237 90:0.977237 91:0.977237 92:0.977237 93:0.977237 94:0.977237 95:0.977237 96:0.977237 97:0.977237 98:0.977237 99:0.977237 100:0.977237 101:0.977237 102:0.977237 103:0.977237 104:0.977237 105:0.977237 106:0.977237 107:0.977237 108:0.977237 109:0.977237 110:0.977237 111:0.977237 112:0.977237 113:0.977237 114:0.977237 115:0.977237 116:0.977237 117:0.977237 118:0.977237 119:0.977237 120:0.977237 121:0.977237 122:0.977237 123:0.977237 124:0.977237 125:0.977237 126:0.977237 127:0.977237 128:0.977237 129:0.977237 130:0.977237 131:0.977237 132:0.977237 133:0.977237 134:0.977237 135:0.977237 136:0.977237 137:0.977237 138:0.977237 139:0.977237 140:0.977237 141:0.977237 142:0.977237 143:0.977237 144:0.977237 145:0.977237 146:0.977237 147:0.977237 148:0.977237 149:0.977237 150:0.977237 151:0.977237 152:0.977237 153:0.977237 154:0.977237 155:0.977237 156:0.977237 157:0.977237 158:0.977237 159:0.977237 160:0.977237 161:0.977237 162:0.977237 163:0.977237 164:0.977237 165:0.977237 166:0.977237 167:0.977237 168:0.977237 169:0.977237 170:0.977237 171:0.977237 172:0.977237 173:0.977237 174:0.977237 175:0.977237 176:0.977237 177:0.977237 178:0.977237 179:0.977237 180:0.977237 181:0.977237 182:0.977237 183:0.977237 184:0.977237 185:0.977237 186:0.977237 187:0.977237 188:0.977237 189:0.977237 190:0.977237 191:0.977237 192:0.977237 193:0.977237 194:0.977237 195:0.977237 196:0.977237 197:0.977237 198:0.977237 199:0.977237 200:0.977237 201:0.977237 202:0.977237 203:0.977237 204:0.977237 205:0.977237 206:0.977237 207:0.977237 208:0.977237 209:0.977237 210:0.977237 211:0.977237 212:0.977237 213:0.977237 214:0.977237 215:0.977237 216:0.977237 217:0.977237 218:0.977237 219:0.977237 220:0.977237 221:0.977237 222:0.977237 223:0.977237 224:0.977237 225:0.977237 226:0.977237 227:0.977237 228:0.977237 229:0.977237 230:0.977237 231:0.977237 232:0.977237 233:0.977237 234:0.977237 235:0.977237 236:0.977237 237:0.977237 238:0.977237 239:0.977237 240:0.977237 241:0.977237 242:0.977237 243:0.977237 244:0.977237 245:0.977237 246:0.977237 247:0.977237 248:0.977237 249:0.977237 250:0.977237 251:0.977237 252:0.977237 253:0.977237 254:0.977237 255:0.977237 256:0.977237 257:0.977237 258:0.977237 259:0.977237 260:0.977237 261:0.977237 262:0.977237 263:0.977237 264:0.977237 265:0.977237 266:0.977237 267:0.977237 268:0.977237 269:0.977237 270:0.977237 271:0.977237 272:0.977237 273:0.977237 274:0.977237 275:0.977237 276:0.977237 277:0.977237 278:0.977237 279:0.977237 280:0.977237 281:0.977237 282:0.977237 283:0.977237 284:0.977237 285:0.977237 286:0.977237 287:0.977237 288:0.977237 289:0.977237 290:0.977237 291:0.977237 292:0.977237 293:0.977237 294:0.977237 295:0.977237 296:0.977237 297:0.977237 298:0.977237 299:0.977237 300:0.977237 301:0.977237 302:0.977237 303:0.977237 304:0.977237 305:0.977237 306:0.977237 307:0.977237 308:0.977237 309:0.977237 310:0.977237 311:0.977237 312:0.977237 313:0.977237 314:0.977237 315:0.977237 316:0.977237 317:0.977237 318:0.977237 319:0.977237 320:0.977237 321:0.977237 322:0.977237 323:0.977237 324:0.977237 325:0.977237 326:0.977237 327:0.977237 328:0.977237 329:0.977237 330:0.977237 331:0.977237 332:0.977237 333:0.977237 334:0.977237 335:0.977237 336:0.977237 337:0.977237 338:0.977237 339:0.977237 340:0.977237 341:0.977237 342:0.977237 343:0.977237 344:0.977237 345:0.977237 346:0.977237 347:0.977237 348:0.977237 349:0.977237 350:0.977237 351:0.977237 352:0.977237 353:0.977237 354:0.977237 355:0.977237 356:0.977237 357:0.977237 358:0.977237 359:0.977237 360:0.977237 361:0.977237 362:0.977237 363:0.977237 364:0.977237 365:0.977237 366:0.977237 367:0.977237 368:0.977237 369:0.977237 370:0.977237 371:0.977237 372:0.977237 373:0.977237 374:0.977237 375:0.977237 376:0.977237 377:0.977237 378:0.977237 379:0.977237 380:0.977237 381:0.977237 382:0.977237 383:0.977237 384:0.977237 385:0.977237 386:0.977237 387:0.977237 388:0.977237 389:0.977237 390:0.977237 391:0.977237 392:0.977237 393:0.977237 394:0.977237 395:0.977237 396:0.977237 397:0.977237 398:0.977237 399:0.977237 400:0.977237 401:0.977237 402:0.977237 403:0.977237 404:0.977237 405:0.977237 406:0.977237 407:0.977237 408:0.977237 409:0.977237 410:0.977237 411:0.977237 412:0.977237 413:0.977237 414:0.977237 415:0.977237 416:0.977237 417:0.977237 418:0.977237 419:0.977237 420:0.977237 421:0.977237 422:0.977237 423:0.977237 424:0.977237 425:0.977237 426:0.977237 427:0.977237 428:0.977237 429:0.977237 430:0.977237 431:0.977237 432:0.977237 433:0.977237 434:0.977237 435:0.977237 436:0.977237 437:0.977237 438:0.977237 439:0.977237 440:0.977237 441:0.977237 442:0.977237 443:0.977237 444:0.977237 445:0.977237 446:0.977237 447:0.977237 448:0.977237 449:0.977237 450:0.977237 451:0.977237 452:0.977237 453:0.977237 454:0.977237 455:0.977237 456:0.977237 457:0.977237 458:0.977237 459:0.977237 460:0.977237 461:0.977237 462:0.977237 463:0.977237 464:0.977237 465:0.977237 466:0.977237 467:0.977237 468:0.977237 469:0.977237 470:0.977237 471:0.977237 472:0.977237 473:0.977237 474:0.977237 475:0.977237 476:0.977237 477:0.977237 478:0.977237 479:0.977237 480:0.977237 481:0.977237 482:0.977237 483:0.977237 484:0.977237 485:0.977237 486:0.977237 487:0.977237 488:0.977237 489:0.977237 490:0.977237 491:0.977237 492:0.977237 493:0.977237 494:0.977237 495:0.977237 496:0.977237 497:0.977237 498:0.977237 499:0.977237
grad_clip_norm = 100.000000

augment_symmetries = 1 0 0
augment_rotation = vertical
augment_noise = 0.001000
augment_occlusion = none
augment_occlusion_ratio = 0.200
augment_occlusion_num = 1
augment_scale_anisotropic = 1
augment_scale_min = 0.800
augment_scale_max = 1.200
augment_color = 0.800

weights_decay = 0.001000
gaussian_decay = 0.001000
batch_averaged_loss = 0
offsets_loss = fitting
offsets_decay = 0.100000
batch_num = 2
max_epoch = 500
epoch_steps = 300
validation_size = 20
snapshot_gap = 25
